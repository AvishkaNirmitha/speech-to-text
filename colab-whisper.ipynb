{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UTTNW6bazcpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'drive/My Drive/1'"
      ],
      "metadata": {
        "id": "74Hs15PFzeLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install whisper\n",
        "! pip install -U openai-whisper\n",
        "!choco install ffmpeg\n",
        "!pip install setuptools-rust"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS30cUAYwJUn",
        "outputId": "af3e93e4-fc85-4cf9-fef2-070008e374c7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting whisper\n",
            "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from whisper) (1.17.0)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41120 sha256=7ed786d50d9e8ffe2afcaced7d30822216d2c96cf3442e5bc979441df1c4e252\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/65/ee/4e6672aabfa486d3341a39a04f8f87c77e5156149299b5a7d0\n",
            "Successfully built whisper\n",
            "Installing collected packages: whisper\n",
            "Successfully installed whisper-1.1.10\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2.0.0->openai-whisper) (3.17.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.1.105)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803373 sha256=662eb39c9547c4fd8f8cebf4b88269c784b0fa02abb560fd3e7fcd7ea5189cf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20240930 tiktoken-0.8.0\n",
            "/bin/bash: line 1: choco: command not found\n",
            "Collecting setuptools-rust\n",
            "  Downloading setuptools_rust-1.10.2-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: setuptools>=62.4 in /usr/local/lib/python3.11/dist-packages (from setuptools-rust) (75.1.0)\n",
            "Collecting semantic-version<3,>=2.8.2 (from setuptools-rust)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Downloading setuptools_rust-1.10.2-py3-none-any.whl (26 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: semantic-version, setuptools-rust\n",
            "Successfully installed semantic-version-2.10.0 setuptools-rust-1.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dvk3-CVPwBT0",
        "outputId": "b94dfd7d-8cf7-433c-fd74-37e006f5ad56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing transcriber at 08:00:17\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loading took: 0:00:24.214966\n",
            "\n",
            "Starting transcription of /content/or.mp3 at 08:00:41\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: English\n",
            "[00:00.640 --> 00:04.400]  Albert Einstein grew up in a middle class family.\n",
            "[00:04.400 --> 00:11.920]  When he was born in his family was scared that something was wrong with him and he had\n",
            "[00:11.920 --> 00:19.120]  very large in miss shape and head.\n",
            "[00:19.120 --> 00:27.000]  But fortunately within the first few weeks the shape of his head became normal.\n",
            "[00:27.000 --> 00:32.620]  But their worries didn't stop there when he was very young.\n",
            "[00:32.620 --> 00:40.760]  His parents thought he might be intellectually disabled because he was very slow to learn\n",
            "[00:40.760 --> 00:49.680]  to talk and did not speak until he was 4 years old.\n",
            "[00:49.680 --> 00:56.980]  At that time he often formed foody sentences in his throat but did not speak his use to\n",
            "[00:56.980 --> 01:05.660]  practice the sentences in his head or whisper them softly under his breath until he got\n",
            "[01:05.660 --> 01:09.540]  them right and then say them aloud.\n",
            "[01:09.540 --> 01:16.920]  Many people believed Einstein would never succeed at anything when he was 5 years old\n",
            "[01:16.920 --> 01:21.800]  his father.\n",
            "[01:21.800 --> 01:26.600]  His interest in the subject when Einstein was only 10 years old.\n",
            "[01:26.600 --> 01:26.660]  He was very good at writing.\n",
            "[01:26.980 --> 01:32.420]  He started educating himself by the age of 12.\n",
            "[01:32.420 --> 01:40.460]  Einstein thought himself geometric by the age of 15.\n",
            "[01:40.460 --> 01:51.540]  He mastered calculus but he hated the disciplined and rigid style of the teachers so he dropped\n",
            "[01:51.540 --> 01:56.600]  out of school and at the age of 15 he left Germany.\n",
            "[01:56.600 --> 01:59.520]  He then went to Germany to avoid military service.\n",
            "[01:59.520 --> 02:09.800]  His parents were worried that their son became school drop out with no employ skills and\n",
            "[02:09.800 --> 02:17.380]  not every promising future but Albert Einstein did not quit his education.\n",
            "[02:17.380 --> 02:20.040]  He applied to Swiss Federal Institute of Technology and believe it or not.\n",
            "[02:20.040 --> 02:21.040]  He failed to get a degree.\n",
            "[02:21.040 --> 02:22.040]  He was a professor in the University of Germany.\n",
            "[02:22.040 --> 02:23.040]  He was a professor of science in the University of Germany.\n",
            "[02:23.040 --> 02:24.040]  He was a professor of science in the University of Germany.\n",
            "[02:24.040 --> 02:25.040]  He was a professor of physics and biology.\n",
            "[02:25.040 --> 02:26.040]  He was a professor of physics and biology.\n",
            "[02:26.040 --> 02:30.480]  He failed the interest exam Albert Einstein.\n",
            "Transcription completed in: 0:00:27.173899\n",
            "\n",
            "--- Full Transcription ---\n",
            " Albert Einstein grew up in a middle class family. When he was born in his family was scared that something was wrong with him and he had very large in miss shape and head. But fortunately within the first few weeks the shape of his head became normal. But their worries didn't stop there when he was very young. His parents thought he might be intellectually disabled because he was very slow to learn to talk and did not speak until he was 4 years old. At that time he often formed foody sentences in his throat but did not speak his use to practice the sentences in his head or whisper them softly under his breath until he got them right and then say them aloud. Many people believed Einstein would never succeed at anything when he was 5 years old his father. His interest in the subject when Einstein was only 10 years old. He was very good at writing. He started educating himself by the age of 12. Einstein thought himself geometric by the age of 15. He mastered calculus but he hated the disciplined and rigid style of the teachers so he dropped out of school and at the age of 15 he left Germany. He then went to Germany to avoid military service. His parents were worried that their son became school drop out with no employ skills and not every promising future but Albert Einstein did not quit his education. He applied to Swiss Federal Institute of Technology and believe it or not. He failed to get a degree. He was a professor in the University of Germany. He was a professor of science in the University of Germany. He was a professor of science in the University of Germany. He was a professor of physics and biology. He was a professor of physics and biology. He failed the interest exam Albert Einstein.\n",
            "\n",
            "--- Transcription Details ---\n",
            "Language Detected: en\n",
            "Approximate Duration: 29 segments\n",
            "Processing Time: 0:00:27\n",
            "\n",
            "Total execution time (including model loading): 0:00:52\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import whisper\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "class OptimizedTranscriber:\n",
        "    def __init__(self, model_name=\"large\"):\n",
        "        self.start_time = time.time()\n",
        "        print(f\"Initializing transcriber at {datetime.now().strftime('%H:%M:%S')}\")\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Enable TensorFloat-32 for better performance on Ampere GPUs\n",
        "        if torch.cuda.is_available():\n",
        "            torch.backends.cuda.matmul.allow_tf32 = True\n",
        "            torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "        # Load model with optimizations\n",
        "        self.model = whisper.load_model(model_name)\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            # Convert model to half precision\n",
        "            self.model = self.model.half()\n",
        "\n",
        "        self.model_load_time = time.time() - self.start_time\n",
        "        print(f\"Model loading took: {timedelta(seconds=self.model_load_time)}\")\n",
        "\n",
        "    def transcribe(self, audio_path):\n",
        "        start_time = time.time()\n",
        "        print(f\"\\nStarting transcription of {audio_path} at {datetime.now().strftime('%H:%M:%S')}\")\n",
        "\n",
        "        try:\n",
        "            # Enable cuda graphs for repeated operations\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.synchronize()\n",
        "\n",
        "            # Use modern autocast syntax\n",
        "            with torch.amp.autocast('cuda' if torch.cuda.is_available() else 'cpu'), \\\n",
        "                 torch.no_grad():\n",
        "\n",
        "                result = self.model.transcribe(\n",
        "                    audio_path,\n",
        "                    fp16=torch.cuda.is_available(),\n",
        "                    verbose=True\n",
        "                )\n",
        "\n",
        "            # Force CUDA synchronization\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.synchronize()\n",
        "\n",
        "            process_time = time.time() - start_time\n",
        "            print(f\"Transcription completed in: {timedelta(seconds=process_time)}\")\n",
        "\n",
        "            return result, process_time\n",
        "\n",
        "        finally:\n",
        "            # Clean up memory\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "    def process_multiple(self, audio_files):\n",
        "        \"\"\"Process multiple audio files sequentially with progress bar\"\"\"\n",
        "        results = []\n",
        "        total_time = 0\n",
        "        start_batch = time.time()\n",
        "\n",
        "        for audio_file in tqdm(audio_files):\n",
        "            result, process_time = self.transcribe(audio_file)\n",
        "            results.append(result)\n",
        "            total_time += process_time\n",
        "\n",
        "        batch_time = time.time() - start_batch\n",
        "        print(f\"\\nBatch Processing Summary:\")\n",
        "        print(f\"Total files processed: {len(audio_files)}\")\n",
        "        print(f\"Total processing time: {timedelta(seconds=batch_time)}\")\n",
        "        print(f\"Average time per file: {timedelta(seconds=batch_time/len(audio_files))}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "def format_time(seconds):\n",
        "    return str(timedelta(seconds=round(seconds)))\n",
        "\n",
        "# Usage\n",
        "def main():\n",
        "    total_start = time.time()\n",
        "\n",
        "    # Initialize transcriber\n",
        "    transcriber = OptimizedTranscriber(model_name=\"large\")\n",
        "\n",
        "    # Single file transcription\n",
        "    result, process_time = transcriber.transcribe(\"/content/or.mp3\")\n",
        "\n",
        "    print(\"\\n--- Full Transcription ---\")\n",
        "    print(result[\"text\"])\n",
        "\n",
        "    print(\"\\n--- Transcription Details ---\")\n",
        "    print(f\"Language Detected: {result['language']}\")\n",
        "    print(f\"Approximate Duration: {len(result['segments'])} segments\")\n",
        "    print(f\"Processing Time: {format_time(process_time)}\")\n",
        "\n",
        "    total_time = time.time() - total_start\n",
        "    print(f\"\\nTotal execution time (including model loading): {format_time(total_time)}\")\n",
        "\n",
        "    # For processing multiple files:\n",
        "    # audio_files = [\"/content/1.mp3\", \"/content/2.mp3\", ...]\n",
        "    # results = transcriber.process_multiple(audio_files)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}